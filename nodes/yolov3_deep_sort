#! /usr/bin/env python
# -*- coding: utf-8 -*-

from __future__ import division, print_function, absolute_import
import rospy
from std_msgs.msg import String
import os
from timeit import time
import warnings
import sys
import cv2
import numpy as np
from PIL import Image
from sensor_msgs.msg import Image as ROSImage
from sensor_msgs.msg import CameraInfo
from yolo3.yolo import YOLO
from cv_bridge import CvBridge, CvBridgeError

from deep_sort import preprocessing
from deep_sort import nn_matching
from deep_sort.detection import Detection
from deep_sort.tracker import Tracker
from tools import generate_detections as gdet
from deep_sort.detection import Detection as ddet
from yolov3_deep_sort.msg import BoundingBox_with_id,BoundingBoxes_with_id
warnings.filterwarnings('ignore')
   

class Publishsers():
    def __init__(self):
        # Definition of the parameters
        max_cosine_distance = 0.3
        nn_budget = None
        self.nms_max_overlap = 1.0  
        # deep_sort 
        model_filename = 'model_data/mars-small128.pb'
        self.encoder = gdet.create_box_encoder(model_filename,batch_size=1)
        metric = nn_matching.NearestNeighborDistanceMetric("cosine", max_cosine_distance, nn_budget)
        self.tracker = Tracker(metric)
        self.fps = 0.0
        # Publisherを作成
        self.publisher = rospy.Publisher('/yolov3_deep_sort/tracking_result', BoundingBoxes_with_id, queue_size=10)
        self.viz_publisher = rospy.Publisher('/yolov3_deep_sort/visualized', ROSImage, queue_size=10)
        # messageの型を作成
	self.image = ROSImage()
        self.visualization_image = ROSImage()
        self.boundingboxwithid = BoundingBox_with_id()
        self.boundingboxeswithid = BoundingBoxes_with_id()
        self.t1 = time.time()

    def make_msg(self, image, yolo):
	#opencvに変換
	bridge = CvBridge()
   	try:
   	    cv_image = bridge.imgmsg_to_cv2(image, desired_encoding='bgr8')
            detected_image=Image.fromarray(cv_image)
            self.t1 = time.time()
            boxs = yolo.detect_image(detected_image)
            features = self.encoder(cv_image,boxs)
            # score to 1.0 here).
            detections = [Detection(bbox, 1.0, feature) for bbox, feature in zip(boxs, features)]
            # Run non-maxima suppression.
            boxes = np.array([d.tlwh for d in detections])
            scores = np.array([d.confidence for d in detections])
            indices = preprocessing.non_max_suppression(boxes, self.nms_max_overlap, scores)
            detections = [detections[i] for i in indices]
            self.boundingboxeswithid = BoundingBoxes_with_id()
            # Call the tracker
            self.tracker.predict()
            self.tracker.update(detections)
            for track in self.tracker.tracks:
                if not track.is_confirmed() or track.time_since_update > 1:
                    continue 
                bbox = track.to_tlbr()
                cv2.rectangle(cv_image, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])),(255,255,255), 2)
                cv2.putText(cv_image, str(track.track_id),(int(bbox[0]), int(bbox[1])),0, 5e-3 * 200, (0,255,0),2)
                self.boundingboxwithid.Class = "person"
                #self.boundingboxwithid.Class = d.confidence
                self.boundingboxwithid.tracking_id = track.track_id # x, y, w, h
                print(bbox)
                self.boundingboxwithid.xmin = bbox[0]
                self.boundingboxwithid.ymin = bbox[1]
                self.boundingboxwithid.xmax = bbox[2]
                self.boundingboxwithid.ymax = bbox[3]
                self.boundingboxeswithid.bounding_boxes_with_id.append(self.boundingboxwithid)    

            for det in detections:
                bbox = det.to_tlbr()
                cv2.rectangle(cv_image,(int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])),(255,0,0), 2)
         
            self.visualization_image.encoding = image.encoding
            self.visualization_image = bridge.cv2_to_imgmsg(cv_image, encoding='bgr8')

        except Exception as e:    
                print(e)
        
        self.fps  = ( self.fps + (1./(time.time()-self.t1)) ) / 2
        print("fps= %f"%(self.fps))
        

    def send_msg(self):
        # messageを送信
        self.publisher.publish(self.boundingboxeswithid)
        self.viz_publisher.publish(self.visualization_image)

class Subscribe_publishers():
    def __init__(self, pub):
       # Subscriberを作成
       self.subscriber = rospy.Subscriber('/camera/image_raw', ROSImage, self.callback)
       # messageの型を作成
       self.image = ROSImage()
       self.pub = pub

    def callback(self, image):
       self.image = image

    def publish_tracking(self, yolo):
       self.pub.make_msg(self.image, yolo)
       # publish
       self.pub.send_msg()

def main(yolo):
    # nodeの立ち上げ
    rospy.init_node('tracking_yolo')
    # クラスの作成
    pub = Publishsers()
    sub = Subscribe_publishers(pub)
    while not rospy.is_shutdown():
        sub.publish_tracking(yolo)
    rospy.spin()

if __name__ == '__main__':
    main(YOLO())
